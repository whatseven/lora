# LoRAæ•°æ®å¤„ç†åˆ†æä¸ä»£ç ä¿®æ”¹æŒ‡å—

## é—®é¢˜åˆ†æ

ä½ æä¾›çš„ä»£ç å’Œunslothç¤ºä¾‹æœ‰æœ¬è´¨å·®å¼‚ï¼š

### ä½ çš„ä»£ç ç‰¹ç‚¹ï¼š
- **ç›´æ¥å¤„ç†tokenå±‚é¢**ï¼šæ‰‹åŠ¨åˆ†è¯ã€æ‹¼æ¥input_idsã€labels
- **ä½¿ç”¨ä¼ ç»ŸSFTæ–¹æ³•**ï¼šéœ€è¦æ‰‹åŠ¨æ„é€ instructionæ¨¡æ¿å’Œlabels
- **è‡ªå®šä¹‰å¯¹è¯æ ¼å¼**ï¼šä½¿ç”¨äº†ç‰¹å®šçš„system promptï¼ˆç”„å¬›è§’è‰²æ‰®æ¼”ï¼‰

### Unslothç¤ºä¾‹ç‰¹ç‚¹ï¼š
- **æ–‡æœ¬å±‚é¢å¤„ç†**ï¼šå…ˆè½¬æ¢ä¸ºconversationæ ¼å¼ï¼Œå†ç”¨chat_template
- **æ¡†æ¶è‡ªåŠ¨å¤„ç†**ï¼šunslothè‡ªåŠ¨å¤„ç†tokenizationå’Œlabels
- **æ ‡å‡†å¯¹è¯æ ¼å¼**ï¼šä½¿ç”¨Qwen3çš„å®˜æ–¹å¯¹è¯æ¨¡æ¿

## æ ¼å¼å¯¹æ¯”

### ä½ çš„ä»£ç è¾“å‡ºæ ¼å¼ï¼š
```
<|im_start|>system
ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›<|im_end|>
<|im_start|>user
{instruction + input}<|im_end|>
<|im_start|>assistant
{output}
```

### Unslothç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼š
```
<|im_start|>user
{instruction + input}<|im_end|>
<|im_start|>assistant
{output}<|im_end|>
```

## æ ¸å¿ƒå·®å¼‚

1. **æ•°æ®å¤„ç†å±‚çº§ä¸åŒ**ï¼š
   - ä½ çš„ä»£ç ï¼šAlpaca â†’ tokens (input_ids/labels)
   - Unslothï¼šAlpaca â†’ conversation â†’ formatted_text

2. **æ¡†æ¶é›†æˆåº¦ä¸åŒ**ï¼š
   - ä½ çš„ä»£ç ï¼šéœ€è¦æ‰‹åŠ¨å¤„ç†æ‰€æœ‰ç»†èŠ‚
   - Unslothï¼šæ¡†æ¶è‡ªåŠ¨å¤„ç†ï¼Œæ›´ç®€æ´é«˜æ•ˆ

## ä¿®æ”¹æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šé€‚é…Unslothæ¡†æ¶ï¼ˆæ¨èï¼‰

```python
def convert_alpaca_to_conversation(example, system_prompt=None):
    """
    å°†Alpacaæ ¼å¼è½¬æ¢ä¸ºconversationæ ¼å¼ï¼Œé€‚é…unsloth
    
    Args:
        example: Alpacaæ ¼å¼çš„å•æ¡æ•°æ®
        system_prompt: å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
    
    Returns:
        list: conversationæ ¼å¼çš„å¯¹è¯
    """
    instruction = example['instruction']
    input_text = example.get('input', '')
    output = example['output']
    
    # æ„é€ ç”¨æˆ·è¾“å…¥
    if input_text.strip():
        user_content = f"{instruction}\n{input_text}"
    else:
        user_content = instruction
    
    # æ„é€ å¯¹è¯
    conversation = []
    
    # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ·»åŠ system role
    if system_prompt:
        conversation.append({"role": "system", "content": system_prompt})
    
    conversation.extend([
        {"role": "user", "content": user_content},
        {"role": "assistant", "content": output}
    ])
    
    return conversation

def process_alpaca_dataset_for_unsloth(dataset_path, system_prompt=None):
    """
    å¤„ç†æ•´ä¸ªAlpacaæ•°æ®é›†ç”¨äºunslothè®­ç»ƒ
    
    Args:
        dataset_path: æ•°æ®é›†æ–‡ä»¶è·¯å¾„
        system_prompt: å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
    
    Returns:
        list: è½¬æ¢åçš„conversationsåˆ—è¡¨
    """
    import json
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    conversations = []
    for example in data:
        conversation = convert_alpaca_to_conversation(example, system_prompt)
        conversations.append(conversation)
    
    return conversations

# ä½¿ç”¨ç¤ºä¾‹
def prepare_dataset_with_custom_system_prompt():
    """ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯å‡†å¤‡æ•°æ®é›†"""
    
    # å®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
    system_prompt = "ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›"
    
    # è½¬æ¢æ•°æ®é›†
    train_conversations = process_alpaca_dataset_for_unsloth(
        "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        system_prompt=system_prompt
    )
    
    # åº”ç”¨å¯¹è¯æ¨¡æ¿
    formatted_texts = tokenizer.apply_chat_template(
        train_conversations,
        tokenize=False,
    )
    
    return formatted_texts

# ä¸ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯çš„ç‰ˆæœ¬
def prepare_dataset_standard():
    """æ ‡å‡†ç‰ˆæœ¬ï¼Œä¸ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯"""
    
    train_conversations = process_alpaca_dataset_for_unsloth(
        "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        system_prompt=None
    )
    
    formatted_texts = tokenizer.apply_chat_template(
        train_conversations,
        tokenize=False,
    )
    
    return formatted_texts
```

### æ–¹æ¡ˆ2ï¼šä¿æŒä½ çš„ä»£ç é£æ ¼ä½†é€‚é…Qwen3

```python
def process_func_for_qwen3(example, tokenizer, system_prompt=None, max_length=2048):
    """
    æ”¹è¿›ç‰ˆçš„å¤„ç†å‡½æ•°ï¼Œé€‚é…Qwen3åˆ†è¯å™¨
    
    Args:
        example: Alpacaæ ¼å¼æ•°æ®
        tokenizer: Qwen3åˆ†è¯å™¨
        system_prompt: å¯é€‰ç³»ç»Ÿæç¤ºè¯
        max_length: æœ€å¤§é•¿åº¦
    
    Returns:
        dict: åŒ…å«input_ids, attention_mask, labelsçš„å­—å…¸
    """
    # æ„é€ ç”¨æˆ·è¾“å…¥
    instruction = example['instruction']
    input_text = example.get('input', '')
    output = example['output']
    
    if input_text.strip():
        user_content = f"{instruction}\n{input_text}"
    else:
        user_content = instruction
    
    # æ„é€ å®Œæ•´çš„å¯¹è¯æ–‡æœ¬
    if system_prompt:
        full_text = f"<|im_start|>system\n{system_prompt}<|im_end|>\n<|im_start|>user\n{user_content}<|im_end|>\n<|im_start|>assistant\n{output}<|im_end|>"
    else:
        full_text = f"<|im_start|>user\n{user_content}<|im_end|>\n<|im_start|>assistant\n{output}<|im_end|>"
    
    # åˆ†åˆ«ç¼–ç instructionå’Œresponseéƒ¨åˆ†
    if system_prompt:
        instruction_part = f"<|im_start|>system\n{system_prompt}<|im_end|>\n<|im_start|>user\n{user_content}<|im_end|>\n<|im_start|>assistant\n"
    else:
        instruction_part = f"<|im_start|>user\n{user_content}<|im_end|>\n<|im_start|>assistant\n"
    
    response_part = f"{output}<|im_end|>"
    
    # ç¼–ç 
    instruction_tokens = tokenizer(instruction_part, add_special_tokens=False)
    response_tokens = tokenizer(response_part, add_special_tokens=False)
    
    # æ‹¼æ¥
    input_ids = instruction_tokens["input_ids"] + response_tokens["input_ids"]
    attention_mask = instruction_tokens["attention_mask"] + response_tokens["attention_mask"]
    labels = [-100] * len(instruction_tokens["input_ids"]) + response_tokens["input_ids"]
    
    # æˆªæ–­å¤„ç†
    if len(input_ids) > max_length:
        input_ids = input_ids[:max_length]
        attention_mask = attention_mask[:max_length]
        labels = labels[:max_length]
    
    return {
        "input_ids": input_ids,
        "attention_mask": attention_mask,
        "labels": labels
    }

# æ‰¹é‡å¤„ç†æ•°æ®é›†
def process_alpaca_dataset_token_level(dataset_path, tokenizer, system_prompt=None, max_length=2048):
    """
    åœ¨tokenå±‚é¢å¤„ç†Alpacaæ•°æ®é›†
    
    Args:
        dataset_path: æ•°æ®é›†è·¯å¾„
        tokenizer: åˆ†è¯å™¨
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        max_length: æœ€å¤§é•¿åº¦
    
    Returns:
        Dataset: å¤„ç†åçš„æ•°æ®é›†
    """
    import json
    from datasets import Dataset
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    processed_data = []
    for example in data:
        processed_example = process_func_for_qwen3(
            example, 
            tokenizer, 
            system_prompt=system_prompt, 
            max_length=max_length
        )
        processed_data.append(processed_example)
    
    return Dataset.from_list(processed_data)
```

### æ–¹æ¡ˆ3ï¼šæ··åˆæ–¹æ¡ˆï¼ˆæœ€çµæ´»ï¼‰

```python
def flexible_alpaca_processor(dataset_path, tokenizer, processing_mode="unsloth", system_prompt=None, max_length=2048):
    """
    çµæ´»çš„Alpacaæ•°æ®å¤„ç†å™¨ï¼Œæ”¯æŒå¤šç§å¤„ç†æ¨¡å¼
    
    Args:
        dataset_path: æ•°æ®é›†è·¯å¾„
        tokenizer: åˆ†è¯å™¨
        processing_mode: "unsloth" æˆ– "token_level"
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        max_length: æœ€å¤§é•¿åº¦
    
    Returns:
        ç›¸åº”æ ¼å¼çš„æ•°æ®é›†
    """
    import json
    from datasets import Dataset
    import pandas as pd
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if processing_mode == "unsloth":
        # ä½¿ç”¨unslothæ–¹å¼å¤„ç†
        conversations = []
        for example in data:
            conversation = convert_alpaca_to_conversation(example, system_prompt)
            conversations.append(conversation)
        
        # åº”ç”¨å¯¹è¯æ¨¡æ¿
        formatted_texts = tokenizer.apply_chat_template(
            conversations,
            tokenize=False,
        )
        
        # åˆ›å»ºæ•°æ®é›†
        data_df = pd.DataFrame({"text": formatted_texts})
        return Dataset.from_pandas(data_df)
    
    elif processing_mode == "token_level":
        # ä½¿ç”¨tokençº§åˆ«å¤„ç†
        processed_data = []
        for example in data:
            processed_example = process_func_for_qwen3(
                example, 
                tokenizer, 
                system_prompt=system_prompt, 
                max_length=max_length
            )
            processed_data.append(processed_example)
        
        return Dataset.from_list(processed_data)
    
    else:
        raise ValueError("processing_mode must be 'unsloth' or 'token_level'")

# ä½¿ç”¨ç¤ºä¾‹
def main_processing_example():
    """ä¸»è¦å¤„ç†ç¤ºä¾‹"""
    from unsloth import FastLanguageModel
    
    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name="unsloth/Qwen3-14B",
        max_seq_length=2048,
        load_in_4bit=True,
    )
    
    # æ–¹å¼1ï¼šä½¿ç”¨unslothæ–¹å¼ï¼ˆæ¨èï¼‰
    dataset_unsloth = flexible_alpaca_processor(
        dataset_path="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        tokenizer=tokenizer,
        processing_mode="unsloth",
        system_prompt="ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›"  # å¯é€‰
    )
    
    # æ–¹å¼2ï¼šä½¿ç”¨tokençº§åˆ«æ–¹å¼
    dataset_token_level = flexible_alpaca_processor(
        dataset_path="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        tokenizer=tokenizer,
        processing_mode="token_level",
        system_prompt="ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›",
        max_length=2048
    )
    
    return dataset_unsloth, dataset_token_level
```

## æ¨èæ–¹æ¡ˆ

**å¼ºçƒˆæ¨èä½¿ç”¨æ–¹æ¡ˆ1ï¼ˆunslothæ–¹å¼ï¼‰**ï¼ŒåŸå› ï¼š

1. **æ›´ç®€æ´**ï¼šunslothæ¡†æ¶è‡ªåŠ¨å¤„ç†å¤æ‚çš„tokenization
2. **æ›´ç¨³å®š**ï¼šå‡å°‘æ‰‹åŠ¨å¤„ç†tokenå¯èƒ½å‡ºç°çš„é”™è¯¯
3. **æ›´é«˜æ•ˆ**ï¼šunslothé’ˆå¯¹è®­ç»ƒè¿›è¡Œäº†ä¼˜åŒ–
4. **æ›´æ ‡å‡†**ï¼šä½¿ç”¨å®˜æ–¹æ¨èçš„å¯¹è¯æ¨¡æ¿

## å®Œæ•´é›†æˆä»£ç 

```python
# å®Œæ•´çš„æ•°æ®å¤„ç†å’Œè®­ç»ƒæµç¨‹
def complete_training_workflow():
    """å®Œæ•´çš„è®­ç»ƒå·¥ä½œæµç¨‹"""
    from unsloth import FastLanguageModel
    from trl import SFTTrainer, SFTConfig
    import pandas as pd
    from datasets import Dataset
    
    # 1. åŠ è½½æ¨¡å‹
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name="unsloth/Qwen3-14B",
        max_seq_length=2048,
        load_in_4bit=True,
    )
    
    # 2. é…ç½®LoRA
    model = FastLanguageModel.get_peft_model(
        model,
        r=64,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj"],
        lora_alpha=64,
        lora_dropout=0,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=3407,
    )
    
    # 3. å¤„ç†æ•°æ®ï¼ˆå¸¦è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼‰
    train_conversations = process_alpaca_dataset_for_unsloth(
        "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        system_prompt="ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›"
    )
    
    # 4. æ ¼å¼åŒ–æ•°æ®
    formatted_texts = tokenizer.apply_chat_template(
        train_conversations,
        tokenize=False,
    )
    
    # 5. åˆ›å»ºæ•°æ®é›†
    data_df = pd.DataFrame({"text": formatted_texts})
    dataset = Dataset.from_pandas(data_df)
    dataset = dataset.shuffle(seed=3407)
    
    # 6. è®­ç»ƒ
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset,
        args=SFTConfig(
            dataset_text_field="text",
            per_device_train_batch_size=4,
            gradient_accumulation_steps=4,
            warmup_steps=10,
            num_train_epochs=1,
            learning_rate=2e-4,
            logging_steps=10,
            optim="adamw_8bit",
            weight_decay=0.01,
            lr_scheduler_type="linear",
            seed=3407,
            output_dir="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora",
            report_to="none",
        ),
    )
    
    # 7. å¼€å§‹è®­ç»ƒ
    trainer.train()
    
    # 8. ä¿å­˜æ¨¡å‹
    model.save_pretrained("/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora")
    tokenizer.save_pretrained("/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora")
    
    return model, tokenizer

if __name__ == "__main__":
    model, tokenizer = complete_training_workflow()
```

è¿™æ ·ä¿®æ”¹åï¼Œä½ çš„ä»£ç å°±èƒ½å®Œç¾é€‚é…unslothæ¡†æ¶ï¼ŒåŒæ—¶ä¿æŒä½ æƒ³è¦çš„è§’è‰²æ‰®æ¼”åŠŸèƒ½ã€‚

---

## ğŸ” Unslothæ•°æ®å¤„ç†è¯¦ç»†åˆ†æ

### Alpacaæ ¼å¼åˆ°å¯¹è¯æ ¼å¼çš„è½¬æ¢é€»è¾‘

#### 1. AlpacaåŸå§‹æ ¼å¼
```json
{
    "instruction": "ç¿»è¯‘ä»¥ä¸‹ä¸­æ–‡åˆ°è‹±æ–‡",
    "input": "ä½ å¥½ï¼Œä¸–ç•Œï¼",
    "output": "Hello, World!"
}
```

#### 2. Unslothå¤„ç†é€»è¾‘åˆ†æ

**ç¬¬ä¸€æ­¥ï¼šåˆå¹¶instructionå’Œinput**
```python
# unslothçš„æ ¸å¿ƒå¤„ç†é€»è¾‘
if input_text.strip():
    user_content = f"{instruction}\n{input_text}"  # ç”¨æ¢è¡Œç¬¦è¿æ¥
else:
    user_content = instruction  # åªæœ‰instructionçš„æƒ…å†µ
```

**ä¸ºä»€ä¹ˆè¦åˆå¹¶ï¼Ÿ**
- `instruction`ï¼šä»»åŠ¡æè¿°/æŒ‡ä»¤
- `input`ï¼šå…·ä½“çš„è¾“å…¥å†…å®¹  
- è¿™ä¸¤è€…å…±åŒæ„æˆäº†ç”¨æˆ·çš„å®Œæ•´è¯·æ±‚
- æ¨¡å‹éœ€è¦ç†è§£ï¼šè¦åšä»€ä¹ˆ(instruction) + å¯¹ä»€ä¹ˆæ“ä½œ(input)

**ç¬¬äºŒæ­¥ï¼šæ„é€ conversationæ ¼å¼**
```python
conversation = [
    {"role": "user", "content": "ç¿»è¯‘ä»¥ä¸‹ä¸­æ–‡åˆ°è‹±æ–‡\nä½ å¥½ï¼Œä¸–ç•Œï¼"},
    {"role": "assistant", "content": "Hello, World!"}
]
```

**ç¬¬ä¸‰æ­¥ï¼šåº”ç”¨chat_template**
```python
formatted_text = tokenizer.apply_chat_template(conversation, tokenize=False)
```

**æœ€ç»ˆè¾“å‡ºæ ¼å¼ï¼š**
```
<|im_start|>user
ç¿»è¯‘ä»¥ä¸‹ä¸­æ–‡åˆ°è‹±æ–‡
ä½ å¥½ï¼Œä¸–ç•Œï¼<|im_end|>
<|im_start|>assistant
Hello, World!<|im_end|>
```

### ä¸ºä»€ä¹ˆåªå‰©ä¸‹userå’Œassistantï¼Ÿ

è¿™æ˜¯**å®Œå…¨æ­£ç¡®**çš„è®¾è®¡ï¼š

1. **instruction + input = userçš„å®Œæ•´è¯·æ±‚**
   - ç”¨æˆ·æä¾›æŒ‡ä»¤(instruction)å’Œæ•°æ®(input)
   - è¿™å°±æ˜¯ä¸€ä¸ªå®Œæ•´çš„user message

2. **output = assistantçš„å›å¤**
   - æ¨¡å‹æ ¹æ®ç”¨æˆ·è¯·æ±‚ç»™å‡ºå›ç­”
   - è¿™å°±æ˜¯assistant message

3. **ç¬¦åˆå¯¹è¯çš„è‡ªç„¶é€»è¾‘**
   - çœŸå®å¯¹è¯ä¸­ï¼Œç”¨æˆ·ä¼šè¯´ï¼š"è¯·å¸®æˆ‘ç¿»è¯‘è¿™å¥è¯ï¼šä½ å¥½ä¸–ç•Œ"
   - è€Œä¸ä¼šåˆ†å¼€è¯´ï¼š"æˆ‘è¦ç¿»è¯‘" + "ä½ å¥½ä¸–ç•Œ"

### å®Œæ•´çš„é€‚é…ä»£ç 

```python
# ===== å®Œæ•´çš„Unslothé€‚é…ä»£ç  =====

import json
import pandas as pd
from datasets import Dataset
from unsloth import FastLanguageModel
from trl import SFTTrainer, SFTConfig

def alpaca_to_conversation(example, system_prompt=None):
    """
    å°†å•æ¡Alpacaæ•°æ®è½¬æ¢ä¸ºconversationæ ¼å¼
    
    Args:
        example: å•æ¡Alpacaæ•°æ® {"instruction": "", "input": "", "output": ""}
        system_prompt: å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
    
    Returns:
        list: conversationæ ¼å¼ [{"role": "user", "content": "..."}, ...]
    """
    instruction = example['instruction']
    input_text = example.get('input', '')  # ç”¨getæ–¹æ³•é˜²æ­¢KeyError
    output = example['output']
    
    # 1. åˆå¹¶instructionå’Œinput
    if input_text.strip():  # å¦‚æœinputä¸ä¸ºç©º
        user_content = f"{instruction}\n{input_text}"
    else:  # å¦‚æœinputä¸ºç©º
        user_content = instruction  # åªæœ‰instructionçš„æƒ…å†µ
    
    # 2. æ„é€ conversation
    conversation = []
    
    # å¯é€‰ï¼šæ·»åŠ ç³»ç»Ÿæç¤ºè¯
    if system_prompt:
        conversation.append({
            "role": "system", 
            "content": system_prompt
        })
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤
    conversation.extend([
        {"role": "user", "content": user_content},
        {"role": "assistant", "content": output}
    ])
    
    return conversation

def process_alpaca_dataset(dataset_path, tokenizer, system_prompt=None):
    """
    å¤„ç†æ•´ä¸ªAlpacaæ•°æ®é›†
    
    Args:
        dataset_path: æ•°æ®é›†æ–‡ä»¶è·¯å¾„
        tokenizer: Qwen3åˆ†è¯å™¨
        system_prompt: å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
    
    Returns:
        Dataset: å¯ç”¨äºè®­ç»ƒçš„æ•°æ®é›†
    """
    # 1. åŠ è½½åŸå§‹æ•°æ®
    print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {dataset_path}")
    with open(dataset_path, 'r', encoding='utf-8') as f:
        alpaca_data = json.load(f)
    print(f"æ•°æ®é›†å¤§å°: {len(alpaca_data)}")
    
    # 2. è½¬æ¢ä¸ºconversationæ ¼å¼
    print("æ­£åœ¨è½¬æ¢ä¸ºconversationæ ¼å¼...")
    conversations = []
    for example in alpaca_data:
        conversation = alpaca_to_conversation(example, system_prompt)
        conversations.append(conversation)
    
    # 3. åº”ç”¨chat_template
    print("æ­£åœ¨åº”ç”¨chat_template...")
    formatted_texts = tokenizer.apply_chat_template(
        conversations,
        tokenize=False,  # è¿”å›æ–‡æœ¬è€Œä¸æ˜¯token
    )
    
    # 4. åˆ›å»ºDataset
    print("æ­£åœ¨åˆ›å»ºDataset...")
    df = pd.DataFrame({"text": formatted_texts})
    dataset = Dataset.from_pandas(df)
    dataset = dataset.shuffle(seed=3407)
    
    print(f"å¤„ç†å®Œæˆï¼æœ€ç»ˆæ•°æ®é›†å¤§å°: {len(dataset)}")
    return dataset

def setup_model_and_training(dataset, output_dir, num_epochs=1, batch_size=4):
    """
    è®¾ç½®æ¨¡å‹å’Œè®­ç»ƒé…ç½®
    
    Args:
        dataset: å¤„ç†å¥½çš„æ•°æ®é›†
        output_dir: è¾“å‡ºç›®å½•
        num_epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
    
    Returns:
        trainer: é…ç½®å¥½çš„è®­ç»ƒå™¨
    """
    # 1. åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½Qwen3-14Bæ¨¡å‹...")
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name="unsloth/Qwen3-14B",
        max_seq_length=2048,
        load_in_4bit=True,
        cache_dir="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/pretrained"
    )
    
    # 2. é…ç½®LoRA
    print("æ­£åœ¨é…ç½®LoRA...")
    model = FastLanguageModel.get_peft_model(
        model,
        r=64,  # A100 32Gå¯ä»¥ä½¿ç”¨è¾ƒå¤§çš„rank
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj"],
        lora_alpha=64,
        lora_dropout=0,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=3407,
    )
    
    # 3. é…ç½®è®­ç»ƒå™¨
    print("æ­£åœ¨é…ç½®è®­ç»ƒå™¨...")
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset,
        args=SFTConfig(
            dataset_text_field="text",  # é‡è¦ï¼šæŒ‡å®šæ–‡æœ¬å­—æ®µ
            per_device_train_batch_size=batch_size,
            gradient_accumulation_steps=4,
            warmup_steps=10,
            num_train_epochs=num_epochs,
            learning_rate=2e-4,
            logging_steps=10,
            optim="adamw_8bit",
            weight_decay=0.01,
            lr_scheduler_type="linear",
            seed=3407,
            output_dir=output_dir,
            report_to="none",
            save_strategy="epoch",
            save_steps=100,
        ),
    )
    
    return trainer, model, tokenizer

# ===== ä¸»è¦ä½¿ç”¨ç¤ºä¾‹ =====

def main_training_pipeline():
    """ä¸»è¦è®­ç»ƒæµç¨‹"""
    
    # æ­¥éª¤1ï¼šåŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼ˆç”¨äºæ•°æ®å¤„ç†ï¼‰
    print("=== æ­¥éª¤1: åŠ è½½åˆ†è¯å™¨ ===")
    _, tokenizer = FastLanguageModel.from_pretrained(
        model_name="unsloth/Qwen3-14B",
        max_seq_length=2048,
        load_in_4bit=True,
    )
    
    # æ­¥éª¤2ï¼šå¤„ç†æ•°æ®é›†
    print("\n=== æ­¥éª¤2: å¤„ç†æ•°æ®é›† ===")
    dataset = process_alpaca_dataset(
        dataset_path="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        tokenizer=tokenizer,
        system_prompt="ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›"  # å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
    )
    
    # æ­¥éª¤3ï¼šè®¾ç½®è®­ç»ƒ
    print("\n=== æ­¥éª¤3: è®¾ç½®è®­ç»ƒ ===")
    trainer, model, tokenizer = setup_model_and_training(
        dataset=dataset,
        output_dir="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora",
        num_epochs=1,
        batch_size=4
    )
    
    # æ­¥éª¤4ï¼šå¼€å§‹è®­ç»ƒ
    print("\n=== æ­¥éª¤4: å¼€å§‹è®­ç»ƒ ===")
    trainer.train()
    
    # æ­¥éª¤5ï¼šä¿å­˜æ¨¡å‹
    print("\n=== æ­¥éª¤5: ä¿å­˜æ¨¡å‹ ===")
    model.save_pretrained("/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora")
    tokenizer.save_pretrained("/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora")
    
    print("\nè®­ç»ƒå®Œæˆï¼")
    return model, tokenizer

# ===== æ•°æ®é¢„è§ˆåŠŸèƒ½ =====

def preview_processed_data(dataset_path, tokenizer, system_prompt=None, num_samples=3):
    """
    é¢„è§ˆå¤„ç†åçš„æ•°æ®æ ¼å¼
    
    Args:
        dataset_path: æ•°æ®é›†è·¯å¾„
        tokenizer: åˆ†è¯å™¨
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        num_samples: é¢„è§ˆæ ·æœ¬æ•°
    """
    print("=== æ•°æ®å¤„ç†é¢„è§ˆ ===")
    
    # åŠ è½½åŸå§‹æ•°æ®
    with open(dataset_path, 'r', encoding='utf-8') as f:
        alpaca_data = json.load(f)
    
    for i in range(min(num_samples, len(alpaca_data))):
        print(f"\n--- æ ·æœ¬ {i+1} ---")
        example = alpaca_data[i]
        
        print("åŸå§‹Alpacaæ ¼å¼:")
        print(f"  instruction: {example['instruction']}")
        print(f"  input: {example.get('input', '')}")
        print(f"  output: {example['output']}")
        
        # è½¬æ¢ä¸ºconversation
        conversation = alpaca_to_conversation(example, system_prompt)
        print(f"\nConversationæ ¼å¼:")
        for msg in conversation:
            print(f"  {msg['role']}: {msg['content']}")
        
        # åº”ç”¨chat_template
        formatted_text = tokenizer.apply_chat_template([conversation], tokenize=False)[0]
        print(f"\næœ€ç»ˆæ ¼å¼åŒ–æ–‡æœ¬:")
        print(formatted_text)
        print("-" * 50)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å…ˆé¢„è§ˆæ•°æ®å¤„ç†æ•ˆæœ
    from unsloth import FastLanguageModel
    _, tokenizer = FastLanguageModel.from_pretrained("unsloth/Qwen3-14B", max_seq_length=2048, load_in_4bit=True)
    
    preview_processed_data(
        dataset_path="/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/dataset/train/alpaca_train.json",
        tokenizer=tokenizer,
        system_prompt="ç°åœ¨ä½ è¦æ‰®æ¼”çš‡å¸èº«è¾¹çš„å¥³äºº--ç”„å¬›",
        num_samples=2
    )
    
    # ç„¶åå¼€å§‹è®­ç»ƒ
    # main_training_pipeline()
```

### å…³é”®è¦ç‚¹æ€»ç»“

1. **instruction + input â†’ user content**ï¼šè¿™æ˜¯æ ‡å‡†åšæ³•ï¼Œç¬¦åˆå¯¹è¯é€»è¾‘
2. **output â†’ assistant content**ï¼šæ¨¡å‹çš„å›å¤
3. **system prompt**ï¼šå¯é€‰çš„è§’è‰²è®¾å®šï¼Œä¼šä½œä¸ºç‹¬ç«‹çš„systemæ¶ˆæ¯
4. **chat_template**ï¼šunslothè‡ªåŠ¨å¤„ç†ï¼Œç”Ÿæˆæ ‡å‡†çš„Qwen3å¯¹è¯æ ¼å¼
5. **å®Œå…¨å…¼å®¹**ï¼šè¿™ç§å¤„ç†æ–¹å¼ä¸ä½ çš„éœ€æ±‚å®Œå…¨å…¼å®¹ï¼Œè¿˜èƒ½äº«å—unslothçš„ä¼˜åŒ–

è¿™æ ·å¤„ç†åï¼Œä½ å°±èƒ½åœ¨ä¿æŒè§’è‰²æ‰®æ¼”åŠŸèƒ½çš„åŒæ—¶ï¼Œå……åˆ†åˆ©ç”¨unslothæ¡†æ¶çš„æ‰€æœ‰ä¼˜åŠ¿ï¼
