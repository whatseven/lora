#!/bin/bash
# Qwen3-14B LoRAå¾®è°ƒä¸€é”®è®­ç»ƒè„šæœ¬

echo "ğŸš€ å¼€å§‹Qwen3-14B LoRAå¾®è°ƒæµç¨‹"
echo "=================================="

# è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡
export HF_ENDPOINT=https://hf-mirror.com
export CUDA_VISIBLE_DEVICES=0
export TOKENIZERS_PARALLELISM=false

echo "ğŸŒ å·²è®¾ç½®HuggingFaceé•œåƒ: $HF_ENDPOINT"

# æ£€æŸ¥Pythonç¯å¢ƒ
if ! command -v python3 &> /dev/null; then
    echo "âŒ é”™è¯¯: æœªæ‰¾åˆ°python3"
    exit 1
fi

# æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
python3 -c "import torch; print('âœ… CUDAå¯ç”¨' if torch.cuda.is_available() else 'âŒ CUDAä¸å¯ç”¨'); print(f'GPUæ•°é‡: {torch.cuda.device_count()}')"

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®é›†æ–‡ä»¶
if [ ! -f "dataset/alpaca_train.json" ]; then
    echo "âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶ dataset/alpaca_train.json"
    echo "è¯·å°†Alpacaæ ¼å¼çš„æ•°æ®é›†æ–‡ä»¶æ”¾åœ¨ dataset/alpaca_train.json"
    exit 1
fi

echo ""
echo "æ­¥éª¤1: å®‰è£…ä¾èµ–"
pip install -r requirements.txt

echo ""
echo "æ­¥éª¤2: å¤„ç†æ•°æ®é›†"
python3 data_processor.py

# æ£€æŸ¥æ•°æ®å¤„ç†æ˜¯å¦æˆåŠŸ
if [ ! -f "dataset/train/alpaca_train.json" ]; then
    echo "âŒ æ•°æ®å¤„ç†å¤±è´¥"
    exit 1
fi

echo ""
echo "æ­¥éª¤3: å¼€å§‹è®­ç»ƒ"
python3 train.py

# æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸ
if [ -d "model/finetuned/lora" ]; then
    echo ""
    echo "ğŸ‰ è®­ç»ƒå®Œæˆï¼"
    echo "æ¨¡å‹å·²ä¿å­˜åœ¨: model/finetuned/lora"
    echo ""
    echo "ç°åœ¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•æ¨¡å‹:"
    echo "python3 test_model.py"
else
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"
    exit 1
fi 