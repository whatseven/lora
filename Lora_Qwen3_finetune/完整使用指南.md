# Qwen3 LoRA微调完整使用指南

本指南提供了Qwen3模型LoRA微调项目的完整使用说明，包括模型训练、版本管理、性能评估等所有环节。

## 📁 项目结构

```
Lora_Qwen3_finetune/
├── model/
│   ├── pretrained/          # 预训练模型缓存
│   └── finetuned/          # 微调模型存储
│       ├── lora_v20241205_143000/    # 版本化目录
│       ├── lora_v20241205_150000/    
│       └── latest -> lora_v20241205_150000/  # 最新版本的软链接
├── dataset/                # 数据集 需手动修改数据集名称为alpaca_train.json,放在dataset目录下，其他部分的数据训练后也需要修改名称，使得后续训练不冲突
├── logs/                   # 日志文件
├── evaluation/             # 评估结果
├── train.py               # 训练脚本
├── benchmark.py           # 评估脚本
├── model_manager.py       # 模型管理工具
└── run_benchmark.sh       # 评估启动脚本
```

## 🚀 快速开始

### 1. 模型训练

#### 基础训练命令
```bash
cd /home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/
conda activate qwen3_finetune
python train.py
```

#### 后台训练（推荐）
```bash
# 完整训练（可能需要几小时）
nohup python train.py > logs/train_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# 查看训练进度
tail -f logs/train_*.log

# 查看所有后台任务
jobs
```

### 2. 模型评估

#### 🌟 性能优化模式（推荐）

**快速评估模式（默认）**
```bash
# 使用默认优化设置：批处理大小2，关闭BERTScore
./run_benchmark.sh --sample_size 50

# 后台运行
nohup ./run_benchmark.sh --sample_size 50 > logs/eval_fast.log 2>&1 &
```

**完整评估模式**
```bash
# 启用BERTScore进行完整评估
./run_benchmark.sh --enable_bertscore --sample_size 50

# 后台运行
nohup ./run_benchmark.sh --enable_bertscore --sample_size 50 > logs/eval_full.log 2>&1 &
```

**自定义批处理大小**
```bash
# 使用更大批处理（需要更多GPU内存）
./run_benchmark.sh --batch_size 4 --sample_size 50

# 使用更小批处理（更节省内存）
./run_benchmark.sh --batch_size 1 --sample_size 50
```

**高级组合示例**
```bash
# 高性能模式：大批处理 + 关闭BERTScore
nohup ./run_benchmark.sh --batch_size 4 --sample_size 100 > logs/eval_fast_batch4.log 2>&1 &

# 平衡模式：中等批处理 + 启用BERTScore  
nohup ./run_benchmark.sh --batch_size 2 --enable_bertscore --sample_size 100 > logs/eval_balanced.log 2>&1 &
```

#### 📊 性能对比

| 模式 | 批处理大小 | BERTScore | 50样本预估时间 | 性能提升 |
|------|-----------|-----------|---------------|----------|
| **快速模式（默认）** | 2 | 关闭 | 30-40分钟 | 3-4x |
| **高速模式** | 4 | 关闭 | 20-30分钟 | 5-6x |
| **完整模式** | 2 | 启用 | 60-90分钟 | 2-3x |
| **原始模式** | 1 | 启用 | 2-3小时 | 1x |

#### 🎯 Sample Size 说明

**关于sample_size参数的行为：**
- 如果测试集有99条数据，设置`--sample_size 300`，实际会使用全部99条数据
- 如果测试集有500条数据，设置`--sample_size 300`，会随机采样300条数据
- 系统会自动选择 `min(actual_data_size, sample_size)` 进行评估
- 随机采样使用固定种子(42)，确保结果可复现

**示例日志输出：**
```
=== 步骤2: 加载测试数据 ===
总测试数据量: 99
使用全部 99 条数据进行评估
✅ 实际评估数据量: 99
```

### 3. 断点续传

#### 评估断点续传
```bash
# 如果评估中断，可以从断点继续
./run_benchmark.sh --checkpoint evaluation/checkpoint.json --sample_size 50

# 后台运行断点续传
nohup ./run_benchmark.sh --checkpoint evaluation/checkpoint.json --sample_size 50 > logs/eval_resume.log 2>&1 &
```

## 🛠️ 高级配置

### 训练配置修改

编辑 `train.py` 文件中的配置：

```305:318:train.py
# LoRA配置
lora_config = LoraConfig(
    r=16,                    # LoRA秩
    lora_alpha=32,          # LoRA alpha参数
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM",
)
```

### 评估配置修改

编辑 `benchmark.py` 文件中的模型路径配置：

```585:605:benchmark.py
# 模型配置选项：
# 选项1: 预训练模型 vs 最新微调模型（默认）
MODEL_A_PATH = None  # 使用默认预训练模型
MODEL_B_PATH = None  # 使用最新微调模型

# 选项2: 预训练模型 vs 指定微调模型
# MODEL_A_PATH = None
# MODEL_B_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_143000"

# 选项3: 两个微调版本对比
# MODEL_A_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_143000"
# MODEL_B_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_150000"
```

## 🔍 模型管理

### 查看模型版本
```bash
python model_manager.py
```

### 模型版本说明
- **版本目录**: `lora_v{YYYYMMDD}_{HHMMSS}` 格式，如 `lora_v20241205_143000`
- **latest链接**: 总是指向最新训练的模型版本
- **核心文件**: `adapter_model.safetensors` (245MB) 包含LoRA参数

## 📊 结果查看

### 评估结果文件
评估完成后，在 `evaluation/` 目录下会生成：
- `evaluation_report_{timestamp}.md` - 详细报告
- `comparison_{timestamp}.png` - 性能对比图表
- `evaluation_results_{timestamp}.json` - 原始数据

### 日志监控
```bash
# 查看训练日志
tail -f logs/train_*.log

# 查看评估日志  
tail -f logs/eval_*.log

# 查看后台任务
jobs
ps aux | grep python
```

## ⚠️ 重要注意事项

### 内存管理
- **批处理大小**: 建议从2开始，根据GPU内存调整
- **Tesla V100-32GB**: 可以使用batch_size=4
- **显存不足时**: 降低batch_size到1

### 兼容性
- 所有新功能与现有 `/model/finetuned/lora` 目录完全兼容
- 版本管理不会影响现有模型文件
- `latest` 链接确保脚本始终使用最新模型

### 性能优化建议
1. **首次评估**: 使用快速模式 `--sample_size 10` 验证环境
2. **日常评估**: 使用默认优化模式 `--sample_size 50`
3. **完整评估**: 仅在最终验证时启用BERTScore
4. **批量实验**: 使用高速模式 `--batch_size 4`

## 🚨 故障排除

### 常见问题

1. **CUDA内存不足**
   ```bash
   # 降低批处理大小
   ./run_benchmark.sh --batch_size 1
   ```

2. **评估中断**
   ```bash
   # 使用断点续传
   ./run_benchmark.sh --checkpoint evaluation/checkpoint.json
   ```

3. **BERTScore计算失败**
   ```bash
   # 关闭BERTScore使用快速模式
   ./run_benchmark.sh  # 默认已关闭
   ```

4. **权限问题**
   ```bash
   chmod +x run_benchmark.sh
   ```

## 📈 性能监控

### GPU使用率监控
```bash
# 实时监控GPU
watch -n 1 nvidia-smi

# 后台记录GPU使用情况
nohup watch -n 5 nvidia-smi >> logs/gpu_monitor.log 2>&1 &
```

### 训练进度监控
```bash
# 监控训练损失
grep "loss" logs/train_*.log | tail -10

# 监控评估进度
grep "样本" logs/eval_*.log | tail -5
```

---

**最后更新**: 2024-12-05  
**版本**: v2.1 - 添加性能优化功能 