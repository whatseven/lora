# Qwen3-14B LoRA微调完整指南

## 🚀 快速开始

### 环境要求
- **硬件**: A100 32G GPU（或同等级别）
- **环境**: Python 3.8+, CUDA 11.8+
- **空间**: 至少50GB可用磁盘空间

### 一键训练与评估
```bash
# 设置环境
export HF_ENDPOINT=https://hf-mirror.com
cd /home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune

# 1. 训练模型
./run_training.sh

# 2. 评估模型
./run_benchmark.sh
```

## 📁 项目结构

```
Lora_Qwen3_finetune/
├── train.py                 # 主训练脚本 ⭐
├── benchmark.py             # 模型评估脚本 ⭐
├── model_manager.py         # 模型管理工具
├── run_training.sh          # 一键训练脚本
├── run_benchmark.sh         # 一键评估脚本
├── dataset/
│   ├── alpaca_train.json    # 原始数据集（需要准备）
│   ├── train/              # 处理后的训练集
│   ├── valid/              # 处理后的验证集
│   └── test/               # 处理后的测试集
├── model/
│   ├── pretrained/         # 预训练模型缓存
│   └── finetuned/          # 微调模型版本目录
│       ├── lora_v20241205_143000/  # 版本化模型
│       ├── latest -> lora_v20241205_143000/  # 最新模型链接
│       └── ...
└── evaluation/
    ├── evaluation_report_*.md      # 评估报告
    ├── comparison_*.png            # 性能对比图
    └── evaluation_results_*.json   # 详细评估数据
```

## 🎯 第一步：准备数据

将你的Alpaca格式数据集放在 `dataset/alpaca_train.json`：

```json
[
    {
        "instruction": "你是一位电池与无人机领域的专家，请你根据你的专业知识回答问题",
        "input": "什么是锂电池的基本工作原理？",
        "output": "锂电池的工作原理基于锂离子在正负极之间的迁移..."
    },
    {
        "instruction": "你是一位电池与无人机领域的专家，请你根据你的专业知识回答问题",
        "input": "如何评估电池的性能指标？",
        "output": "电池性能主要通过以下指标评估：容量、功率密度、循环寿命..."
    }
]
```

## 🔧 第二步：配置训练参数

### 基础配置 - 在 `train.py` 中修改（第305-320行左右）

```python
# ===============================================
# 🎯 模型路径配置 - 在这里修改基础模型路径
# ===============================================

# 选项1: 使用官方预训练模型（首次训练）
BASE_MODEL_PATH = None  # 使用默认预训练模型

# 选项2: 使用本地下载的预训练模型
# BASE_MODEL_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/pretrained/Qwen3-14B"

# 选项3: 使用之前微调的模型继续训练（增量训练）
# BASE_MODEL_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/latest"
# BASE_MODEL_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_143000"

# 模型版本（如果为None则自动生成时间戳）
MODEL_VERSION = None  # 例如: "battery_v1" 或 None

# ===============================================
# 🎯 训练参数配置
# ===============================================

# 模型参数
MAX_SEQ_LENGTH = 1024          # 序列长度 (快速验证用1024，正式训练用2048)

# LoRA参数 
LORA_RANK = 16                 # LoRA rank (快速验证用16，正式训练用64)
LORA_ALPHA = 16                # LoRA alpha (通常等于rank)

# 训练参数
NUM_EPOCHS = 1                 # 训练轮数 (快速验证用1，正式训练用3)
BATCH_SIZE = 2                 # 批次大小 (快速验证用2，正式训练用4)
LEARNING_RATE = 2e-4           # 学习率
```

### 参数调优建议

| 场景 | MAX_SEQ_LENGTH | LORA_RANK | NUM_EPOCHS | BATCH_SIZE | 预期效果 |
|------|----------------|-----------|------------|------------|----------|
| **快速验证** | 512 | 8 | 1 | 1 | 5-10分钟，确认流程 |
| **正常训练** | 1024 | 16 | 1-2 | 2 | 30-60分钟，基础效果 |
| **高质量训练** | 2048 | 64 | 3-5 | 4 | 2-4小时，最佳效果 |

## 🚀 第三步：开始训练

```bash
# 一键训练（推荐）
./run_training.sh

# 或者分步执行
python data_processor.py    # 处理数据
python train.py            # 开始训练
```

**预期输出**：
```
🚀 Qwen3-14B LoRA微调开始
🎯 训练器初始化完成
基础模型: unsloth/Qwen3-14B-unsloth-bnb-4bit
模型版本: 20241205_143000
输出路径: model/finetuned/lora_v20241205_143000

=== 步骤1: 加载基础模型 ===
✅ 模型加载完成

=== 步骤2: 配置LoRA适配器 ===
✅ LoRA配置完成

=== 步骤5: 开始训练 ===
🚀 训练开始...
Epoch 1/1: 100%|██████| 200/200 [30:25<00:00, 0.11it/s, loss=0.654]
✅ 训练完成

=== 步骤6: 保存模型 ===
✅ 模型保存完成
✅ 最新模型链接已创建: model/finetuned/latest

🎉 训练流程全部完成！
```

### 新版本管理系统

每次训练会自动创建版本化目录：
```
model/finetuned/
├── lora_v20241205_143000/    # 第一次训练
├── lora_v20241205_150000/    # 第二次训练
├── lora_vbattery_v1/         # 自定义版本名
├── latest -> lora_v20241205_150000/  # 软链接，始终指向最新模型
└── lora/                     # 兼容旧版本
```

## 📊 第四步：配置评估参数

### 评估配置 - 在 `benchmark.py` 中修改（第585-605行左右）

```python
# ===============================================
# 🎯 模型对比配置 - 在这里修改要对比的模型
# ===============================================

# 选项1: 预训练模型 vs 最新微调模型（默认）
MODEL_A_PATH = None  # 使用默认预训练模型
MODEL_B_PATH = None  # 使用最新微调模型

# 选项2: 预训练模型 vs 指定微调模型
# MODEL_A_PATH = None
# MODEL_B_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_143000"

# 选项3: 两个微调版本对比
# MODEL_A_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_143000"
# MODEL_B_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_150000"

# 选项4: 使用latest链接对比其他版本
# MODEL_A_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/latest"
# MODEL_B_PATH = "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora_v20241205_150000"
```

## 🧪 第五步：开始评估

### 前台运行（适合快速测试）
```bash
# 一键评估（推荐）
./run_benchmark.sh

# 或者自定义参数
./run_benchmark.sh --sample_size 100    # 快速评估
./run_benchmark.sh --sample_size 500    # 详细评估

# 或者直接运行Python脚本
python benchmark.py
```

### 后台运行（适合长时间评估，推荐用于服务器）

```bash
# 创建日志目录
mkdir -p logs

# 后台运行评估（推荐）
nohup ./run_benchmark.sh --sample_size 50 > logs/eval_fast.log 2>&1 &

# 带参数的后台运行
nohup ./run_benchmark.sh --sample_size 200 > logs/benchmark_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# 启动快速评估（20样本，约2小时）
nohup ./run_benchmark.sh --sample_size 20 > logs/eval_quick.log 2>&1 &

# 查看运行状态
ps aux | grep benchmark.py

# 查看实时日志
tail -f logs/benchmark_*.log

# 停止评估
pkill -f benchmark.py

kill -9 <进程ID>

# 2. 验证清理结果（应该没有输出）
ps aux | grep benchmark | grep -v grep
```

**预期输出**：
```
🚀 Qwen3模型对比评估开始
📊 对比配置:
  模型A: 默认预训练模型
  模型B: 最新微调模型

🔧 评估器初始化完成
输出标识: pretrained_vs_lora_v20241205_143000

=== 步骤1: 加载模型 ===
✅ 模型A加载完成
✅ 模型B加载完成

=== 步骤3: 模型评估 ===
评估进度: 100%|███████| 100/100 [25:32<00:00, 15.32s/samples]

🎉 评估完成！
📊 评估报告: evaluation/evaluation_report_pretrained_vs_lora_v20241205_143000.md
📈 对比图表: evaluation/comparison_pretrained_vs_lora_v20241205_143000.png

📈 模型对比结果:
BLEU-4: +0.094 (+42.5%)
ROUGE-L: +0.144 (+40.7%)
BERTScore-F1: +0.085 (+10.9%)
```

### 长时间评估最佳实践

**⚠️ 服务器评估推荐流程**：
```bash
# 1. 创建屏幕会话（可选，双重保险）
screen -S qwen_eval

# 2. 进入项目目录
cd /home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune

# 3. 启动后台评估
nohup ./run_benchmark.sh --sample_size 300 > logs/eval_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# 4. 记录进程ID和日志文件
echo "进程ID: $(ps aux | grep benchmark.py | grep -v grep | awk '{print $2}')"
echo "日志文件: $(ls -t logs/eval_*.log | head -1)"

# 5. 断开连接前检查
tail -f logs/eval_*.log  # Ctrl+C退出查看

# 6. 安全断开连接
exit  # 或者 Ctrl+A+D (如果使用screen)
```

**📱 远程监控命令**：
```bash
# 重新连接服务器后查看状态
ssh your_server
cd /home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune

# 检查是否还在运行
ps aux | grep benchmark.py

# 查看最新日志
tail -f logs/eval_*.log

# 查看评估进度（如果有checkpoint.json）
ls -la evaluation/checkpoint.json
```

### 评估指标说明

| 指标 | 说明 | 范围 | 意义 |
|------|------|------|------|
| **BLEU-4** | 衡量生成文本流畅度和准确性 | 0-1 | 值越高表示与参考答案越相似 |
| **ROUGE-L** | 衡量关键信息匹配度 | 0-1 | 值越高表示捕捉关键信息越好 |
| **BERTScore-F1** | 衡量语义相似性 | 0-1 | 值越高表示语义理解越准确 |

## 🔧 第六步：模型管理

### 查看所有模型
```bash
python model_manager.py
```

**功能菜单**：
```
🚀 Qwen3 模型管理工具
1. 查看所有模型
2. 显示训练配置模板
3. 设置最新模型
4. 查看当前最新模型
5. 退出
```

### 核心模型文件说明

每个模型目录包含：
- **`adapter_model.safetensors`** - 核心LoRA权重文件（245MB）
- `adapter_config.json` - LoRA配置
- `training_config.json` - 训练配置记录（新增）
- 分词器相关文件

## 🎯 常用工作流程

### 首次训练流程
```bash
# 1. 准备数据集到 dataset/alpaca_train.json
# 2. 保持默认配置（train.py和benchmark.py都无需修改）
./run_training.sh
./run_benchmark.sh
```

### 增量训练流程
```bash
# 1. 修改 train.py 配置
# BASE_MODEL_PATH = "/path/to/previous/model" 或 "latest"
# MODEL_VERSION = "v2"

# 2. 运行训练
./run_training.sh

# 3. 对比新旧版本
# 修改 benchmark.py 配置两个模型路径
./run_benchmark.sh
```

### 多版本对比
```bash
# 修改 benchmark.py 中的两个模型路径
# MODEL_A_PATH = "/path/to/model1"
# MODEL_B_PATH = "/path/to/model2"
./run_benchmark.sh
```

## ⚠️ 常见问题与解决方案

### 训练相关问题

**1. 内存不足**
```python
# 在 train.py 中调整参数
BATCH_SIZE = 1           # 降低批次大小
MAX_SEQ_LENGTH = 512     # 缩短序列长度
LORA_RANK = 8           # 降低LoRA rank
```

**2. 训练速度慢**
```python
# 快速验证配置
NUM_EPOCHS = 1
BATCH_SIZE = 1
MAX_SEQ_LENGTH = 512
# 数据集只用前100条
```

**3. 模型下载失败**
```bash
# 确保设置了镜像
export HF_ENDPOINT=https://hf-mirror.com
# 删除缓存重新下载
rm -rf model/pretrained/
```

### 评估相关问题

**1. 找不到模型**
```bash
# 使用模型管理工具检查
python model_manager.py
# 确认模型路径正确
ls -la model/finetuned/latest/
```

**2. 评估速度慢**
```bash
# 减少评估样本
./run_benchmark.sh --sample_size 50

# 长时间评估使用nohup避免连接断开
nohup ./run_benchmark.sh > logs/benchmark.log 2>&1 &
```

**3. 缺少测试数据**
```bash
# 确保数据处理完成
python data_processor.py
ls dataset/test/alpaca_test.json
```

## 💡 性能优化建议

### 数据质量优化
- **多样性**: 确保训练数据覆盖目标应用场景
- **质量**: 人工审核关键样本，确保指令-回答匹配
- **数量**: 建议至少500-1000条高质量样本

### 训练策略优化
- **渐进式**: 先用小数据集验证，再扩大规模
- **监控**: 观察loss曲线，避免过拟合
- **迭代**: 根据评估结果调整训练参数

### 评估策略优化
- **多维度**: 结合三个指标综合判断
- **定性**: 人工检查生成样本质量
- **对比**: 使用多种对比模式验证改进效果

---

🎉 **现在您已经掌握了完整的Qwen3-14B微调与评估流程！**

核心记住三点：
1. **配置路径**: 在 `train.py` 和 `benchmark.py` 中修改对应配置
2. **一键运行**: 使用 `./run_training.sh` 和 `./run_benchmark.sh`
3. **版本管理**: 系统自动管理模型版本，支持灵活对比 