#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒåæ¨¡å‹æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•å¾®è°ƒåçš„Qwen3æ¨¡å‹
"""

import torch
from unsloth import FastLanguageModel
from transformers import TextStreamer
import os

class ModelTester:
    def __init__(self, model_path=None):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.model_path = model_path or "/home/ubuntu/ZJQ/ai_report/Lora_Qwen3_finetune/model/finetuned/lora"
        self.model = None
        self.tokenizer = None
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒåçš„æ¨¡å‹"""
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
        
        if not os.path.exists(self.model_path):
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {self.model_path}")
            print("è¯·å…ˆè¿è¡Œ python train.py å®Œæˆè®­ç»ƒ")
            return False
        
        try:
            self.model, self.tokenizer = FastLanguageModel.from_pretrained(
                model_name=self.model_path,
                max_seq_length=2048,
                load_in_4bit=True,
            )
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def chat(self, user_input, max_new_tokens=512, temperature=0.7, top_p=0.8, top_k=20):
        """ä¸æ¨¡å‹å¯¹è¯"""
        if self.model is None or self.tokenizer is None:
            print("è¯·å…ˆåŠ è½½æ¨¡å‹")
            return
        
        # æ„é€ è¾“å…¥
        messages = [{"role": "user", "content": user_input}]
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        inputs = self.tokenizer(text, return_tensors="pt").to("cuda")
        
        print(f"\nç”¨æˆ·: {user_input}")
        print("åŠ©æ‰‹: ", end="", flush=True)
        
        # ç”Ÿæˆå›å¤
        streamer = TextStreamer(self.tokenizer, skip_prompt=True)
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                do_sample=True,
                streamer=streamer,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        return outputs
    
    def batch_test(self, test_questions=None):
        """æ‰¹é‡æµ‹è¯•å¤šä¸ªé—®é¢˜"""
        if test_questions is None:
            test_questions = [
                "è¯·ä»‹ç»ä¸€ä¸‹é”‚ç¦»å­ç”µæ± çš„å·¥ä½œåŸç†",
                "æ— äººæœºçš„é£è¡Œæ§åˆ¶ç³»ç»Ÿæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
                "ç”µæ± ç®¡ç†ç³»ç»Ÿ(BMS)çš„ä¸»è¦åŠŸèƒ½æœ‰å“ªäº›ï¼Ÿ",
                "æ— äººæœºåœ¨ç”µæ± ç»­èˆªæ–¹é¢é¢ä¸´ä»€ä¹ˆæŒ‘æˆ˜ï¼Ÿ",
                "å¦‚ä½•æé«˜æ— äººæœºç”µæ± çš„èƒ½é‡å¯†åº¦ï¼Ÿ",
                "è¯·è§£é‡Šä¸€ä¸‹æ— äººæœºçš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯",
                "ç”µæ± çƒ­ç®¡ç†ç³»ç»Ÿçš„é‡è¦æ€§æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æ— äººæœºåœ¨ç‰©æµé…é€ä¸­çš„åº”ç”¨å‰æ™¯å¦‚ä½•ï¼Ÿ",
            ]
        
        print("=== æ‰¹é‡æµ‹è¯•å¼€å§‹ ===")
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯• {i}/{len(test_questions)}")
            print('='*60)
            self.chat(question, max_new_tokens=256)
        
        print(f"\n{'='*60}")
        print("âœ… æ‰¹é‡æµ‹è¯•å®Œæˆ")
    
    def interactive_chat(self):
        """äº¤äº’å¼å¯¹è¯"""
        print("=== äº¤äº’å¼å¯¹è¯æ¨¡å¼ ===")
        print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
        print("è¾“å…¥ 'clear' æ¸…å±")
        print("-" * 40)
        
        while True:
            try:
                user_input = input("\nç”¨æˆ·: ").strip()
                
                if user_input.lower() in ['exit', 'quit']:
                    print("å†è§ï¼")
                    break
                
                if user_input.lower() == 'clear':
                    os.system('clear' if os.name == 'posix' else 'cls')
                    continue
                
                if not user_input:
                    print("è¯·è¾“å…¥é—®é¢˜")
                    continue
                
                self.chat(user_input)
                
            except KeyboardInterrupt:
                print("\n\nå†è§ï¼")
                break
            except Exception as e:
                print(f"å‘ç”Ÿé”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Qwen3æ¨¡å‹æµ‹è¯•å™¨")
    print("=" * 40)
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = ModelTester()
    
    # åŠ è½½æ¨¡å‹
    if not tester.load_model():
        return
    
    print("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. æ‰¹é‡æµ‹è¯• (é»˜è®¤é—®é¢˜)")
    print("2. è‡ªå®šä¹‰é—®é¢˜æµ‹è¯•")
    print("3. äº¤äº’å¼å¯¹è¯")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()
        
        if choice == '1' or choice == '':
            tester.batch_test()
        
        elif choice == '2':
            question = input("è¯·è¾“å…¥æµ‹è¯•é—®é¢˜: ").strip()
            if question:
                print("\n" + "="*60)
                tester.chat(question)
        
        elif choice == '3':
            tester.interactive_chat()
        
        else:
            print("æ— æ•ˆé€‰æ‹©")
    
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•ä¸­æ–­")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main() 